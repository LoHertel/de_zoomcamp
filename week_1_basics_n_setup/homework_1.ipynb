{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://root:root@localhost/ny_taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 Homework\n",
    "\n",
    "*Source: https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_1_basics_n_setup/homework.md*\n",
    "\n",
    "In this homework we'll prepare the environment \n",
    "and practice with terraform and SQL\n",
    "\n",
    "## Question 1. Google Cloud SDK\n",
    "\n",
    "Install Google Cloud SDK. What's the version you have? \n",
    "\n",
    "To get the version, run `gcloud --version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud SDK 369.0.0\n",
      "bq 2.0.72\n",
      "core 2022.01.14\n",
      "gsutil 5.6\n"
     ]
    }
   ],
   "source": [
    "!gcloud --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Cloud account \n",
    "\n",
    "Create an account in Google Cloud and create a project.\n",
    "\n",
    "\n",
    "## Question 2. Terraform \n",
    "\n",
    "Now install terraform and go to the terraform directory (`https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/week_1_basics_n_setup/1_terraform_gcp/terraform`)\n",
    "\n",
    "After that, run\n",
    "\n",
    "* `terraform init`\n",
    "* `terraform plan`\n",
    "* `terraform apply` \n",
    "\n",
    "Apply the plan and copy the output (after running `apply`) to the form.\n",
    "\n",
    "It should be the entire output - from the moment you typed `terraform init` to the very end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "(base) [terraform (main %=)]$ terraform init\n",
    "\n",
    "Initializing the backend...\n",
    "\n",
    "Successfully configured the backend \"local\"! Terraform will automatically\n",
    "use this backend unless the backend configuration changes.\n",
    "\n",
    "Initializing provider plugins...\n",
    "- Finding latest version of hashicorp/google...\n",
    "- Installing hashicorp/google v4.7.0...\n",
    "- Installed hashicorp/google v4.7.0 (signed by HashiCorp)\n",
    "\n",
    "Terraform has created a lock file .terraform.lock.hcl to record the provider\n",
    "selections it made above. Include this file in your version control repository\n",
    "so that Terraform can guarantee to make the same selections by default when\n",
    "you run \"terraform init\" in the future.\n",
    "\n",
    "Terraform has been successfully initialized!\n",
    "\n",
    "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
    "any changes that are required for your infrastructure. All Terraform commands\n",
    "should now work.\n",
    "\n",
    "If you ever set or change modules or backend configuration for Terraform,\n",
    "rerun this command to reinitialize your working directory. If you forget, other\n",
    "commands will detect it and remind you to do so if necessary.\n",
    "(base) [terraform (main %=)]$ terraform plan\n",
    "var.project\n",
    "  Your GCP Project ID\n",
    "\n",
    "  Enter a value: xxxxxxx\n",
    "\n",
    "\n",
    "Terraform used the selected providers to generate the following execution plan.\n",
    "Resource actions are indicated with the following symbols:\n",
    "  + create\n",
    "\n",
    "Terraform will perform the following actions:\n",
    "\n",
    "  # google_bigquery_dataset.dataset will be created\n",
    "  + resource \"google_bigquery_dataset\" \"dataset\" {\n",
    "      + creation_time              = (known after apply)\n",
    "      + dataset_id                 = \"trips_data_all\"\n",
    "      + delete_contents_on_destroy = false\n",
    "      + etag                       = (known after apply)\n",
    "      + id                         = (known after apply)\n",
    "      + last_modified_time         = (known after apply)\n",
    "      + location                   = \"europe-west6\"\n",
    "      + project                    = \"xxxxxxx\"\n",
    "      + self_link                  = (known after apply)\n",
    "\n",
    "      + access {\n",
    "          + domain         = (known after apply)\n",
    "          + group_by_email = (known after apply)\n",
    "          + role           = (known after apply)\n",
    "          + special_group  = (known after apply)\n",
    "          + user_by_email  = (known after apply)\n",
    "\n",
    "          + view {\n",
    "              + dataset_id = (known after apply)\n",
    "              + project_id = (known after apply)\n",
    "              + table_id   = (known after apply)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "  # google_storage_bucket.data-lake-bucket will be created\n",
    "  + resource \"google_storage_bucket\" \"data-lake-bucket\" {\n",
    "      + force_destroy               = true\n",
    "      + id                          = (known after apply)\n",
    "      + location                    = \"EUROPE-WEST6\"\n",
    "      + name                        = \"dtc_data_lake_xxxxxxx\"\n",
    "      + project                     = (known after apply)\n",
    "      + self_link                   = (known after apply)\n",
    "      + storage_class               = \"STANDARD\"\n",
    "      + uniform_bucket_level_access = true\n",
    "      + url                         = (known after apply)\n",
    "\n",
    "      + lifecycle_rule {\n",
    "          + action {\n",
    "              + type = \"Delete\"\n",
    "            }\n",
    "\n",
    "          + condition {\n",
    "              + age                   = 30\n",
    "              + matches_storage_class = []\n",
    "              + with_state            = (known after apply)\n",
    "            }\n",
    "        }\n",
    "\n",
    "      + versioning {\n",
    "          + enabled = true\n",
    "        }\n",
    "    }\n",
    "\n",
    "Plan: 2 to add, 0 to change, 0 to destroy.\n",
    "\n",
    "───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "Note: You didn't use the -out option to save this plan, so Terraform can't\n",
    "guarantee to take exactly these actions if you run \"terraform apply\" now.\n",
    "\n",
    "(base) [terraform (main %=)]$ terraform apply\n",
    "var.project\n",
    "  Your GCP Project ID\n",
    "\n",
    "  Enter a value: xxxxxxx\n",
    "\n",
    "\n",
    "Terraform used the selected providers to generate the following execution plan.\n",
    "Resource actions are indicated with the following symbols:\n",
    "  + create\n",
    "\n",
    "Terraform will perform the following actions:\n",
    "\n",
    "  # google_bigquery_dataset.dataset will be created\n",
    "  + resource \"google_bigquery_dataset\" \"dataset\" {\n",
    "      + creation_time              = (known after apply)\n",
    "      + dataset_id                 = \"trips_data_all\"\n",
    "      + delete_contents_on_destroy = false\n",
    "      + etag                       = (known after apply)\n",
    "      + id                         = (known after apply)\n",
    "      + last_modified_time         = (known after apply)\n",
    "      + location                   = \"europe-west6\"\n",
    "      + project                    = \"xxxxxxx\"\n",
    "      + self_link                  = (known after apply)\n",
    "\n",
    "      + access {\n",
    "          + domain         = (known after apply)\n",
    "          + group_by_email = (known after apply)\n",
    "          + role           = (known after apply)\n",
    "          + special_group  = (known after apply)\n",
    "          + user_by_email  = (known after apply)\n",
    "\n",
    "          + view {\n",
    "              + dataset_id = (known after apply)\n",
    "              + project_id = (known after apply)\n",
    "              + table_id   = (known after apply)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "  # google_storage_bucket.data-lake-bucket will be created\n",
    "  + resource \"google_storage_bucket\" \"data-lake-bucket\" {\n",
    "      + force_destroy               = true\n",
    "      + id                          = (known after apply)\n",
    "      + location                    = \"EUROPE-WEST6\"\n",
    "      + name                        = \"dtc_data_lake_xxxxxxx\"\n",
    "      + project                     = (known after apply)\n",
    "      + self_link                   = (known after apply)\n",
    "      + storage_class               = \"STANDARD\"\n",
    "      + uniform_bucket_level_access = true\n",
    "      + url                         = (known after apply)\n",
    "\n",
    "      + lifecycle_rule {\n",
    "          + action {\n",
    "              + type = \"Delete\"\n",
    "            }\n",
    "\n",
    "          + condition {\n",
    "              + age                   = 30\n",
    "              + matches_storage_class = []\n",
    "              + with_state            = (known after apply)\n",
    "            }\n",
    "        }\n",
    "\n",
    "      + versioning {\n",
    "          + enabled = true\n",
    "        }\n",
    "    }\n",
    "\n",
    "Plan: 2 to add, 0 to change, 0 to destroy.\n",
    "\n",
    "Do you want to perform these actions?\n",
    "  Terraform will perform the actions described above.\n",
    "  Only 'yes' will be accepted to approve.\n",
    "\n",
    "  Enter a value: yes\n",
    "\n",
    "google_bigquery_dataset.dataset: Creating...\n",
    "google_storage_bucket.data-lake-bucket: Creating...\n",
    "google_bigquery_dataset.dataset: Creation complete after 2s [id=projects/xxxxxxx/datasets/trips_data_all]\n",
    "google_storage_bucket.data-lake-bucket: Creation complete after 2s [id=dtc_data_lake_xxxxxxx]\n",
    "\n",
    "Apply complete! Resources: 2 added, 0 changed, 0 destroyed.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Postgres \n",
    "\n",
    "Run Postgres and load data as shown in the videos\n",
    "\n",
    "We'll use the yellow taxi trips from January 2021:\n",
    "\n",
    "```bash\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2021-01.csv\n",
    "```\n",
    "\n",
    "You will also need the dataset with zones:\n",
    "\n",
    "```bash \n",
    "wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
    "```\n",
    "\n",
    "Download this data and put it to Postgres\n",
    "\n",
    "## Question 3. Count records \n",
    "\n",
    "How many taxi trips were there on January 15?\n",
    "\n",
    "Consider only trips that started on January 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://root:***@localhost/ny_taxi\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>53024</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(53024,)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM public.yellow_taxi_data\n",
    "WHERE DATE(tpep_pickup_datetime) = '2021-01-15';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Largest tip for each day\n",
    "\n",
    "Find the largest tip for each day. \n",
    "On which day it was the largest tip in January?\n",
    "\n",
    "Use the pick up time for your calculations.\n",
    "\n",
    "(note: it's not a typo, it's \"tip\", not \"trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://root:***@localhost/ny_taxi\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>date</th>\n",
       "        <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2021-01-20</td>\n",
       "        <td>1140.44</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.date(2021, 1, 20), 1140.44)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT DATE(tpep_pickup_datetime), MAX(tip_amount)\n",
    "FROM public.yellow_taxi_data\n",
    "GROUP BY DATE(tpep_pickup_datetime)\n",
    "ORDER BY MAX(tip_amount) DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Most popular destination\n",
    "\n",
    "What was the most popular destination for passengers picked up \n",
    "in central park on January 14?\n",
    "\n",
    "Use the pick up time for your calculations.\n",
    "\n",
    "Enter the zone name (not id). If the zone name is unknown (missing), write \"Unknown\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://root:***@localhost/ny_taxi\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Zone</th>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Upper East Side South</td>\n",
       "        <td>97</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Upper East Side South', 97)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT z_do.\"Zone\", COUNT(z_do.\"Zone\")\n",
    "FROM yellow_taxi_data t\n",
    "LEFT JOIN taxi_zones z_pu\n",
    "ON t.\"PULocationID\" = z_pu.\"LocationID\"\n",
    "LEFT JOIN taxi_zones z_do\n",
    "ON t.\"DOLocationID\" = z_do.\"LocationID\"\n",
    "WHERE DATE(t.tpep_pickup_datetime) = '2021-01-14'\n",
    "AND z_pu.\"Zone\" = 'Central Park'\n",
    "GROUP BY z_do.\"Zone\"\n",
    "ORDER BY COUNT(z_do.\"Zone\") DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Most expensive locations\n",
    "\n",
    "What's the pickup-dropoff pair with the largest \n",
    "average price for a ride (calculated based on `total_amount`)?\n",
    "\n",
    "Enter two zone names separated by a slash\n",
    "\n",
    "For example:\n",
    "\n",
    "\"Jamaica Bay / Clinton East\"\n",
    "\n",
    "If any of the zone names are unknown (missing), write \"Unknown\". For example, \"Unknown / Clinton East\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://root:***@localhost/ny_taxi\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>pickup-dropoff pair</th>\n",
       "        <th>avg_amount</th>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Alphabet City / Unknown</td>\n",
       "        <td>490.54400000000015</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Alphabet City / Unknown', 490.54400000000015, 5)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT CONCAT(z_pu.\"Zone\", ' / ', z_do.\"Zone\") AS \"pickup-dropoff pair\", \n",
    "       AVG(t.total_amount) AS avg_amount, \n",
    "       COUNT(*)\n",
    "FROM yellow_taxi_data t\n",
    "LEFT JOIN taxi_zones z_pu\n",
    "ON t.\"PULocationID\" = z_pu.\"LocationID\"\n",
    "LEFT JOIN taxi_zones z_do\n",
    "ON t.\"DOLocationID\" = z_do.\"LocationID\"\n",
    "GROUP BY z_pu.\"Zone\", z_do.\"Zone\"\n",
    "ORDER BY AVG(t.total_amount) DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the solutions\n",
    "\n",
    "* Form for submitting: https://forms.gle/yGQrkgRdVbiFs8Vd7\n",
    "* You can submit your homework multiple times. In this case, only the last submission will be used. \n",
    "\n",
    "Deadline: 24 January, 17:00 CET"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ce6d0bbf4e0b4ce1c4cf418097ee189306903545ed86997f05eb3be7ea98865"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlplaw': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
